{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-29T22:33:12.510065Z",
     "start_time": "2025-01-29T22:33:12.478513Z"
    }
   },
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from pycocotools.coco import COCO\n",
    "import shutil\n",
    "import sys\n",
    "import supervision as sv"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T22:33:13.623344Z",
     "start_time": "2025-01-29T22:33:12.512441Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sys.path.insert(1, '../..')\n",
    "\n",
    "from data_processing.data_proc_lib.annotations import data_skeleton\n",
    "from data_processing.data_proc_lib.transforms import do_paste\n",
    "from data_processing.data_proc_lib.utilities import create_directories"
   ],
   "id": "ae932ea1777cac4e",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This notebook will create annotations (masks and bounding boxes) for generated galaxies.\n",
    "\n",
    "Set the following:\n",
    "\n",
    "`THRESHOLD`: Pixel values below this value will be removed. This is to remove low levels of background noise that often appears surrounding images generated by GANs or VAEs. Recommended settings: 15 for VAE-generated galaxies, 25 for GAN-generated galaxies.\n",
    "\n",
    "`category`: Which galaxy category we're annotating.\n",
    "\n",
    "`OUTPUT_DIR`: Target output directory for annotated images.\n",
    "\n",
    "`image_dir`: Input directory containing images (of a single category) to be annotated."
   ],
   "id": "19384f82a199a8e0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T22:33:13.661125Z",
     "start_time": "2025-01-29T22:33:13.659965Z"
    }
   },
   "cell_type": "code",
   "source": [
    "THRESHOLD = 15  # Use 25 for GAN, 15 for VAE\n",
    "IMAGE_HEIGHT = 450\n",
    "IMAGE_WIDTH = 450"
   ],
   "id": "175353d146b236cc",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "OUTPUT_DIR = \"/mnt/data/rgn_ijcnn/augmented/vae_by_class\"\n",
    "create_directories(OUTPUT_DIR, split_by_class=True)\n",
    "category = 3\n",
    "image_dir = os.path.join(\n",
    "    f\"/home/matt/Documents/Project/repos/vae-torch-celeba/rand-cat-{category}-kld-0.05/generated/random\", str(category),\n",
    "    \"train\")\n",
    "image_files = [f.name for f in os.scandir(image_dir) if not f.name.startswith('.')]"
   ],
   "id": "d2c0b367bbdcb308",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T22:33:13.756899Z",
     "start_time": "2025-01-29T22:33:13.754052Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_anno_from_image(image_path, id):\n",
    "    anno = {}\n",
    "    segmentations = []\n",
    "\n",
    "    image_array = np.array(Image.open(image_path))\n",
    "    mask = np.logical_or(np.logical_or(image_array[:, :, 0] > THRESHOLD, image_array[:, :, 1] > THRESHOLD),\n",
    "                         image_array[:, :, 2] > THRESHOLD)\n",
    "\n",
    "    # Create polygons from transformed masks\n",
    "    polygons = sv.mask_to_polygons(mask)\n",
    "    for p in polygons:\n",
    "        segmentations.append([float(s) for s in p.flatten()])\n",
    "\n",
    "    anno[\"segmentation\"] = segmentations\n",
    "\n",
    "    tight_bbox_xyxy = sv.mask_to_xyxy(\n",
    "        mask.reshape([1, IMAGE_HEIGHT, IMAGE_WIDTH]))\n",
    "    width = int(tight_bbox_xyxy[0][2] - tight_bbox_xyxy[0][0])\n",
    "    height = int(tight_bbox_xyxy[0][3] - tight_bbox_xyxy[0][1])\n",
    "\n",
    "    tight_bbox_xywh = [\n",
    "        int(tight_bbox_xyxy[0][0]),\n",
    "        int(tight_bbox_xyxy[0][1]),\n",
    "        width,\n",
    "        height,\n",
    "    ]\n",
    "\n",
    "    transformed_bbox_area = tight_bbox_xywh[2] * tight_bbox_xywh[3]\n",
    "\n",
    "    anno[\"num_keypoints\"] = 0\n",
    "    anno[\"area\"] = transformed_bbox_area\n",
    "    anno[\"iscrowd\"] = 0\n",
    "    anno[\"image_id\"] = id + 1\n",
    "    anno[\"bbox\"] = tight_bbox_xywh\n",
    "    #anno[\"keypoints\"] = []\n",
    "    anno[\"category_id\"] = category + 1\n",
    "    anno[\"id\"] = id + 1\n",
    "\n",
    "    return anno"
   ],
   "id": "51bc04ae1313f07e",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-29T22:33:13.803721Z",
     "start_time": "2025-01-29T22:33:13.801722Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def save_image(generated_image_path, output_dir):\n",
    "    output_image_dir = os.path.join(output_dir, \"train\")\n",
    "    output_image_file_path = os.path.join(output_image_dir, f\"generated_{id + 1}.png\")\n",
    "    image = Image.open(generated_image_path)\n",
    "\n",
    "    image = np.array(image).astype(np.uint8)\n",
    "\n",
    "    offset = int((450 - 32) / 2)\n",
    "    large_image_array = np.zeros((450, 450, 3), dtype=np.uint8)\n",
    "    large_image_array[offset:(offset + 32), offset:(offset + 32), :] = image\n",
    "\n",
    "    cleaned_image_array = do_paste(np.zeros((450, 450, 3), dtype=np.uint8), large_image_array, threshold=THRESHOLD)\n",
    "\n",
    "    Image.fromarray(cleaned_image_array).save(output_image_file_path)\n",
    "\n",
    "    return output_image_file_path"
   ],
   "id": "d90adc72999da65a",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "original_annos = os.path.join(\"/mnt/data/rgn_ijcnn/cleaned\", \"annotations\", \"train.json\")\n",
    "augmented_data = data_skeleton(original_annos)\n",
    "output_path = os.path.join(OUTPUT_DIR, str(category))\n",
    "print(output_path)\n",
    "\n",
    "for id, image in enumerate(image_files):\n",
    "    generated_image_path = os.path.join(image_dir, image)\n",
    "    output_image_path = save_image(generated_image_path, output_path)\n",
    "\n",
    "    anno = create_anno_from_image(output_image_path, id)\n",
    "\n",
    "    aug_image_data = {\n",
    "        \"file_name\": f\"generated_{id + 1}.png\",\n",
    "        \"height\": 450,\n",
    "        \"width\": 450,\n",
    "        \"id\": id + 1\n",
    "    }\n",
    "\n",
    "    # Append the image-related data to the annotation.\n",
    "    augmented_data[\"images\"].append(aug_image_data)\n",
    "\n",
    "    augmented_data[\"annotations\"].append(anno)\n",
    "\n",
    "# Write the annotations file.\n",
    "train_annos_filepath = os.path.join(output_path, \"annotations\", \"train.json\")\n",
    "\n",
    "with open(train_annos_filepath, \"w\") as f:\n",
    "    json.dump(augmented_data, f, ensure_ascii=False, indent=4)\n"
   ],
   "id": "3643a680d24f752",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
